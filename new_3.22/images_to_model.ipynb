{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:50:19.193878: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from get_landmarks import get_landmarks\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"clean_data/TEST_TRAIN/\"\n",
    "poses = [os.path.basename(d) for d in glob.glob(\"clean_data/TEST_TRAIN/*\")]\n",
    "\n",
    "all_imgs_path = []\n",
    "for pose in poses:\n",
    "    curr_path = path + pose + \"/\"\n",
    "    all_imgs_path += (glob.glob(f\"{curr_path}*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do Not Run unless necessary!\n",
    "# data = []\n",
    "# for path in tqdm(all_imgs_path, desc=\"Processing Images...\"):\n",
    "#     landmarks = get_landmarks(cv2.imread(path))\n",
    "#     landmarks.append(path)\n",
    "#     data.append(landmarks)\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df.to_csv(\"raw_kp_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lmk0_x</th>\n",
       "      <th>lmk0_y</th>\n",
       "      <th>lmk1_x</th>\n",
       "      <th>lmk1_y</th>\n",
       "      <th>lmk2_x</th>\n",
       "      <th>lmk2_y</th>\n",
       "      <th>lmk3_x</th>\n",
       "      <th>lmk3_y</th>\n",
       "      <th>lmk4_x</th>\n",
       "      <th>lmk4_y</th>\n",
       "      <th>...</th>\n",
       "      <th>lmk28_y</th>\n",
       "      <th>lmk29_x</th>\n",
       "      <th>lmk29_y</th>\n",
       "      <th>lmk30_x</th>\n",
       "      <th>lmk30_y</th>\n",
       "      <th>lmk31_x</th>\n",
       "      <th>lmk31_y</th>\n",
       "      <th>lmk32_x</th>\n",
       "      <th>lmk32_y</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385088</td>\n",
       "      <td>0.702528</td>\n",
       "      <td>0.364045</td>\n",
       "      <td>0.705285</td>\n",
       "      <td>0.361666</td>\n",
       "      <td>0.700772</td>\n",
       "      <td>0.359247</td>\n",
       "      <td>0.696249</td>\n",
       "      <td>0.364545</td>\n",
       "      <td>0.705934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768468</td>\n",
       "      <td>0.898328</td>\n",
       "      <td>0.851075</td>\n",
       "      <td>0.870051</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.781881</td>\n",
       "      <td>0.930616</td>\n",
       "      <td>0.763475</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>clean_data/TEST_TRAIN/downdog/00000372.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715758</td>\n",
       "      <td>0.547609</td>\n",
       "      <td>0.729912</td>\n",
       "      <td>0.527488</td>\n",
       "      <td>0.729571</td>\n",
       "      <td>0.523913</td>\n",
       "      <td>0.728997</td>\n",
       "      <td>0.520017</td>\n",
       "      <td>0.728891</td>\n",
       "      <td>0.527579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664694</td>\n",
       "      <td>0.307465</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>0.261937</td>\n",
       "      <td>0.680302</td>\n",
       "      <td>0.380548</td>\n",
       "      <td>0.670513</td>\n",
       "      <td>0.336641</td>\n",
       "      <td>0.713165</td>\n",
       "      <td>clean_data/TEST_TRAIN/downdog/00000414.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530292</td>\n",
       "      <td>0.608646</td>\n",
       "      <td>0.514618</td>\n",
       "      <td>0.623104</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>0.621608</td>\n",
       "      <td>0.506621</td>\n",
       "      <td>0.619859</td>\n",
       "      <td>0.517501</td>\n",
       "      <td>0.626247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729783</td>\n",
       "      <td>0.889003</td>\n",
       "      <td>0.781900</td>\n",
       "      <td>0.853871</td>\n",
       "      <td>0.763474</td>\n",
       "      <td>0.806643</td>\n",
       "      <td>0.812826</td>\n",
       "      <td>0.792238</td>\n",
       "      <td>0.797374</td>\n",
       "      <td>clean_data/TEST_TRAIN/downdog/00000158.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lmk0_x    lmk0_y    lmk1_x    lmk1_y    lmk2_x    lmk2_y    lmk3_x  \\\n",
       "0  0.385088  0.702528  0.364045  0.705285  0.361666  0.700772  0.359247   \n",
       "1  0.715758  0.547609  0.729912  0.527488  0.729571  0.523913  0.728997   \n",
       "2  0.530292  0.608646  0.514618  0.623104  0.510664  0.621608  0.506621   \n",
       "\n",
       "     lmk3_y    lmk4_x    lmk4_y  ...   lmk28_y   lmk29_x   lmk29_y   lmk30_x  \\\n",
       "0  0.696249  0.364545  0.705934  ...  0.768468  0.898328  0.851075  0.870051   \n",
       "1  0.520017  0.728891  0.527579  ...  0.664694  0.307465  0.655862  0.261937   \n",
       "2  0.619859  0.517501  0.626247  ...  0.729783  0.889003  0.781900  0.853871   \n",
       "\n",
       "    lmk30_y   lmk31_x   lmk31_y   lmk32_x   lmk32_y  \\\n",
       "0  0.811650  0.781881  0.930616  0.763475  0.904605   \n",
       "1  0.680302  0.380548  0.670513  0.336641  0.713165   \n",
       "2  0.763474  0.806643  0.812826  0.792238  0.797374   \n",
       "\n",
       "                                    file_name  \n",
       "0  clean_data/TEST_TRAIN/downdog/00000372.jpg  \n",
       "1  clean_data/TEST_TRAIN/downdog/00000414.jpg  \n",
       "2  clean_data/TEST_TRAIN/downdog/00000158.jpg  \n",
       "\n",
       "[3 rows x 67 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_kp_data.csv\")\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "columns = []\n",
    "for lmk in [f\"lmk{x}\" for x in range(33)]:\n",
    "    for each in [\"x\", \"y\"]:\n",
    "        columns.append(f\"{lmk}_{each}\")\n",
    "columns.append(\"file_name\")\n",
    "\n",
    "df = df.rename(columns=dict(zip(df.columns, columns)))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_X and df_y from df\n",
    "\n",
    "df[\"pose\"] = df[\"file_name\"].apply(lambda x: x.split(\"/\")[2])\n",
    "df[\"pose\"] = df[\"pose\"].astype(\"category\")\n",
    "df_X = df.drop(columns=[\"pose\", \"file_name\"])\n",
    "df_y = df[\"pose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop landmarks 1, 3, 4, 6\n",
    "2. Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmk_to_drop = [1, 3, 4, 6]\n",
    "# cols_to_drop = []\n",
    "# for lmk in lmk_to_drop:\n",
    "#     for each in [\"x\", \"y\"]:\n",
    "#         cols_to_drop.append(f\"lmk{str(lmk)}_{each}\")\n",
    "\n",
    "cols_to_drop = ['lmk1_x','lmk1_y','lmk3_x','lmk3_y','lmk4_x','lmk4_y','lmk6_x','lmk6_y']\n",
    "cols_to_scale = [col for col in df_X.columns if col not in cols_to_drop]\n",
    "\n",
    "transformers = [\n",
    "    (\"drop\", \"drop\", cols_to_drop),\n",
    "    (\"scale\", StandardScaler(), cols_to_scale)\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers=transformers, remainder=\"passthrough\")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    column_transformer\n",
    ")\n",
    "\n",
    "df_X_transformed = pipeline.fit_transform(df_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoga-pose-detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
